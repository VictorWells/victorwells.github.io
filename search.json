[{"title":"关于一次sql优化的心得","url":"/2020/03/27/sql/","content":"<h3 id=\"遇见的问题\"><a href=\"#遇见的问题\" class=\"headerlink\" title=\"遇见的问题\"></a>遇见的问题</h3><p>之前写了一个调度，是专门用来处理一些数据的，调度配置如下图：<br><img src=\"/2020/03/27/sql/2020-03-27-10-22-03.png\" alt=\"\"><br><img src=\"/2020/03/27/sql/2020-03-27-10-26-02.png\" alt=\"\"></p>\n<p>但是今天客服反应，说很久之前的数据都还没有提报，导致人工工作量巨增。<br>于是我把sql拿出来查了一把，发现居然堆积了巨多数据，之前都没有那么多数据的，我想应该和最近的三八大促有关，而且调度处理的这部分数据都是和售后有关的。<br>    我分析了以下原因：<br>        <em>1、调度扫描数据的sql每次limit500，很明显，目前的数据已经超出当初预计的范围</em><br>        <em>2、调度之所以limit500，是因为怕sql一次性查出太多数据，执行增加耗时，导致连接超时（可以从页面输入url触发调度，超时时间为60秒）</em><br>        <em>3、调度每两小时执行一次，可能两小时内产生的数据已经成倍增加，导致数据处理不及时，形成数据堆积</em></p>\n<h3 id=\"探索过程\"><a href=\"#探索过程\" class=\"headerlink\" title=\"探索过程\"></a>探索过程</h3><p>我把sql拿出来看了一下执行计划，不看不知道，一看吓一跳，居然扫了全表<br><img src=\"/2020/03/27/sql/2020-03-27-10-41-08.png\" alt=\"\"><br>执行计划和测试库不一样，很明显，测试库的数据并没有生产那么多，所以从测试环境是看不出来效果的。那么问题来了，当时为什么没有把sql拿出来放生产跑一把看看执行计划？嘿嘿，没想到啊没想到…而且当时这个需求情况比较急，没多少时间，不过说到底，还是大意了(自己的锅，甩是没有用的)</p>\n<p>蹩整这些没有用的了，赶紧把sql优化好才是关键。于是我开始从sql的各种条件中寻找突破口，首先看看执行计划，哪些表走了索引，哪些表没有走索引：<br><img src=\"/2020/03/27/sql/2020-03-27-10-48-30.png\" alt=\"\"><br>从图片可以看出，就这个follow表没有走索引，那肯定就是因为这个表的相关条件导致扫描全表。<br>于是我把这个表的查询条件找出来：<br><img src=\"/2020/03/27/sql/2020-03-27-10-52-50.png\" alt=\"\"><br>这个表的过滤条件只有这一个，于是我又去看了一把表结构，看看这个表都有哪些索引：<br><img src=\"/2020/03/27/sql/2020-03-27-10-54-10.png\" alt=\"\"><br>所以，到这里已经很明显了吧，我的查询条件并没有在索引的列表中。那怎么办呢？只能看看能不能把索引的字段加上了。<br>于是我从业务的角度出发，去寻找看看有没有参考的价值，有的时候真是就怕碰到问题不思考，不会变换角度思考问题，这还真给我找到一个突破口。既然sql捞的是待提报的数据，那么提报时间必然是空值，刚好索引列表中又有一个提报时间的索引，于是我把这个条件加上，再看看执行计划：<br><img src=\"/2020/03/27/sql/2020-03-27-10-59-47.png\" alt=\"\"><br><img src=\"/2020/03/27/sql/2020-03-27-11-01-35.png\" alt=\"\"><br>搞定收工！</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>通过这次的亲身经历，我觉得sql优化执行计划很重要！先看走没走索引，如果没走，看看是哪个表没走索引，然后就是想办法让它走索引，其实sql优化无非就是索引的问题。</p>\n","tags":["sql优化"]},{"title":"关于一次遇见updade导致的死锁问题记录","url":"/2020/01/16/hello-world/","content":"<h3 id=\"遇见的问题\"><a href=\"#遇见的问题\" class=\"headerlink\" title=\"遇见的问题\"></a>遇见的问题</h3><p>今天在生产遇见一个问题，服务器报错，日志记录如下图：<br><img src=\"/2020/01/16/hello-world/2020-01-16-15-14-53.png\" alt=\"\"><br>日志提示为 update table where id=? 造成的死锁。</p>\n<h3 id=\"探索过程\"><a href=\"#探索过程\" class=\"headerlink\" title=\"探索过程\"></a>探索过程</h3><p>询问DBA这个时间段有些什么操作，都有哪些sql在执行，根据sql执行形况找到对应的业务代码，查看代码是否有问题，代码业务层很简单，并没有什么复杂的逻辑，就是一个dubbo服务调用，被调用方就一个select，然后一个遍历，遍历里update，没有其他逻辑了。最后并没有在代码层面找到问题所在。<br>于是想让测试同学帮忙重新一下报错场景，然而测试也并未重现出来。通过我一步步的尝试与排查，初步定位到了原因：生产和测试环境的数据差异比较大，同样的条件查询，生产数据量很大，而测试环境数据量比较少，导致线上select耗时过长，造成dubbo接口调用超时(超时时间设置为120秒)。而测试环境并不会造成超时的情况，所以测试环境没有线上的问题。<br>第一步已经确认，但是为什么会造成死锁的发生？<br>于是继续发掘真相，突然想到RPC服务一般都会有重试机制，虽然这部分相关的配置我并不了解(因为我们项目都是分工进行的，而且我也只是在原来的基础上修改，配置这部分我恰好没有接触到，所以并不清楚具体的配置是什么)，但是我觉得很可能和这个有关，于是询问同事相关的配置以及重试机制是怎样的。同事说我们的重试机制为自动重试2次。突然我就豁然开朗了。于是得到以下结论：</p>\n<ul>\n<li>线上慢sql查询耗时过长，在select之后遍历update的时候，服务调用超时了。</li>\n<li>dubbo服务调用超时，并不会终止当前的进程，他还会继续执行。</li>\n<li>因为存在事务，这里的事务为数据库层的事务，上一个事务还未commit，这时候又自动重试，导致select脏读，又遍历update，这时候两个update where id=? ,id重复了，导致死锁。(根据id进行update只会锁行)<br>到此，问题原因水落石出。</li>\n</ul>\n<h3 id=\"解决方式\"><a href=\"#解决方式\" class=\"headerlink\" title=\"解决方式\"></a>解决方式</h3><p>讲讲最后的解决措施吧，首先sql没办法优化，也不好优化，故忽略sql优化这部分。<br>既然不能优化sql，那还是得保证查询耗时得问题呀，于是对查询进行了分页，每次限制查多少条数据，这样也算减少了一些查询耗时了，然后再在调用方增加声明式事务，避免重试机制的数据脏读。</p>\n<h3 id=\"尾言\"><a href=\"#尾言\" class=\"headerlink\" title=\"尾言\"></a>尾言</h3><p>这就是我本次遇见及解决问题的全过程，分享一下，加深理解。</p>\n","tags":["dubbo 事务"]}]